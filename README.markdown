# Kinyarwanda Hate Speech Detection App

A machine learning app to detect **hate**, **normal**, or **sarcasm** in Kinyarwanda text using a transformer model. Includes a Chrome extension (Developer Mode) for real-time classification.

---

## üöÄ Features

- Detects `hate`, `normal`, or `sarcasm` in Kinyarwanda
- Uses a fine-tuned `afro-xlmr-mini` transformer model
- Highlights key words with attention-based explanations
- Web interface for text analysis
- Chrome extension for live web integration

---

## üìÅ Project Structure

```
project/
‚îÇ
‚îú‚îÄ‚îÄ app.py                    # Flask app
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Procfile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ css/
‚îÇ    ‚îú‚îÄ‚îÄ dashboard.css
‚îÇ    ‚îú‚îÄ‚îÄ index.css
‚îÇ    ‚îú‚îÄ‚îÄ login.css
‚îÇ    ‚îú‚îÄ‚îÄ register.css
‚îÇ    ‚îú‚îÄ‚îÄ moderator_dashboard.css
‚îÇ    ‚îú‚îÄ‚îÄ verify.css
‚îÇ    ‚îú‚îÄ‚îÄ forgot_password.css
‚îÇ    ‚îú‚îÄ‚îÄ reset_password.css
‚îú‚îÄ‚îÄ templates/
‚îÇ    ‚îú‚îÄ‚îÄ dashboard.html
‚îÇ    ‚îú‚îÄ‚îÄ index.html
‚îÇ    ‚îú‚îÄ‚îÄ login.html
‚îÇ    ‚îú‚îÄ‚îÄ register.html
‚îÇ    ‚îú‚îÄ‚îÄ moderator_dashboard.html
‚îÇ    ‚îú‚îÄ‚îÄ verify.html
‚îÇ    ‚îú‚îÄ‚îÄ forgot_password.html
‚îÇ    ‚îú‚îÄ‚îÄ reset_password.html
‚îú‚îÄ‚îÄ model/
‚îÇ    ‚îú‚îÄ‚îÄ kinyamodel2.ipynb     # Model training notebook
‚îÇ    ‚îú‚îÄ‚îÄ kinyarwanda_hard_texts.csv
‚îÇ    ‚îú‚îÄ‚îÄ realistic_kinyarwanda_hate_sarcasm_normal.csv
‚îÇ    ‚îú‚îÄ‚îÄ label_encoder.pkl
‚îÇ    ‚îú‚îÄ‚îÄ kinyarwanda-hatespeech-model/  # Transformer model directory
‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ config.json
‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ tokenizer_config.json
‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ sentencepiece.bpe.model
‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ special_tokens_map.json
‚îú‚îÄ‚îÄ RHD_extension/    # Chrome extension source files
‚îÇ    ‚îú‚îÄ‚îÄ manifest.json
‚îÇ    ‚îú‚îÄ‚îÄ popup.html
‚îÇ    ‚îú‚îÄ‚îÄ popup.js
‚îÇ    ‚îú‚îÄ‚îÄ icon.png
‚îÇ    ‚îú‚îÄ‚îÄ content.js
‚îÇ    ‚îú‚îÄ‚îÄ background.js
```

---

## üõ†Ô∏è Installation

1. **Clone the Repository**
   ```bash
   git clone https://github.com/Olamieee/kinyarwanda-hate-speech-app.git
   cd kinyarwanda-hate-speech-app
   ```

2. **Create Virtual Environment**
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Windows
   source venv/bin/activate  # macOS/Linux
   ```

3. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **(Optional) Fine-Tune Model**
   ```bash
   jupyter notebook model/kinyamodel2.ipynb
   ```
   - Loads `kinyarwanda_hard_texts.csv` and `realistic_kinyarwanda_hate_sarcasm_normal.csv`
   - Fine-tunes `afro-xlmr-mini`
   - Saves model to `model/kinyarwanda-hatespeech-model/` and `label_encoder.pkl`
   - Use a GPU (e.g., Colab) for faster training

5. **Run the App**
   ```bash
   python app.py
   ```
   Visit `http://localhost:5000`

---

## üß© Chrome Extension (Developer Mode)

1. **Load Extension**
   - Go to `chrome://extensions/`
   - Enable **Developer Mode**
   - Click **Load Unpacked**
   - Select `RHD_extension/`

2. **Use Extension**
   - Highlight Kinyarwanda text on a webpage
   - Click extension icon and **Analyze**
   - View `hate`, `normal`, or `sarcasm` result with key words

   > Ensure the app is running locally (`http://localhost:5000`) or deployed (`https://kinyarwanda-hatespeech-detection.onrender.com`).

---

## üîç Model Summary

- **Algorithm**: Fine-tuned `afro-xlmr-mini` transformer
- **Tokenizer**: Sentencepiece (`sentencepiece.bpe.model`)
- **Explainability**: Attention-based word importance
- **Classes**: `hate`, `normal`, `sarcasm`
- **Metrics**: See `kinyamodel2.ipynb` for accuracy and F1 scores

---

## üß™ Example Usage

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import joblib

# Load model and tokenizer
model_path = "model/kinyarwanda-hatespeech-model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)
label_encoder = joblib.load("model/kinyarwanda-hatespeech-model/label_encoder.pkl")

def predict(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        pred = torch.argmax(outputs.logits, dim=1).item()
    return label_encoder.inverse_transform([pred])[0]

# Example
text = "Urwanko rw'abanyarwanda ruzamara iteka"
print(predict(text))  # e.g., 'normal'
```

---

## üõ°Ô∏è License

MIT License